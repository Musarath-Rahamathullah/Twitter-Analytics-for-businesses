{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"> TWITTER ANALYTICS APPLICATION </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#load libraries\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import wget\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import webbrowser\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost, string\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "from datetime import datetime\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "import plotly.tools as plotly_tools\n",
    "\n",
    "from plotly.offline import init_notebook_mode,plot\n",
    "from plotly import tools\n",
    "\n",
    "import chart_studio \n",
    "chart_studio.tools.set_credentials_file(username='musarath', api_key='hN1B3D9TpmpUSxRG5iKy')\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# included flask\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "import import_ipynb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA DOWNLOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweets from twitter \n",
    "def twitter_credentials(hashtag):\n",
    "    # Twitter API credentials\n",
    "    \n",
    "    consumer_key = 'J5CMEPQjJLnm2Wo3IQs8V2qzr'\n",
    "    consumer_secret ='nUGDFg461iszY7IXfiwVRE9dE9WfdDDNh6TG3Wrw82nYhyRi55'\n",
    "    access_key = '203862650-MKbLxvUyNurxQDjxhiIndLbr3fH2ZX2GazuOyrFl'\n",
    "    access_secret =  'NMI6hhi8rmJ6jIhQbhNgsjAB7pwrYuIzcg4tHB5J4unHz'\n",
    "\n",
    "    # Create the api endpoint\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "    twts = []\n",
    "    print(\"Downloading in progress...\")\n",
    "    for tweet in tweepy.Cursor( api.search, q='#' + hashtag  + \"-filter:retweets\",\n",
    "                                #api.search, q='#' + hashtag + since:2019-09-01 + until:2019-9-22 +  \"-filter:retweets\" ,\n",
    "                               lang=\"en\").items(10000):\n",
    "        twts.append([str(tweet.created_at),tweet.text.encode('utf-8')])\n",
    "    print(\"Downloading completed!\")\n",
    "\n",
    "     \n",
    "    return twts\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "def write_tweets_to_file(hash,tweets):\n",
    "    with open('tweets_with_hashtag_'+hash+'.csv', 'w',encoding='utf8',newline='') as the_file:\n",
    "        writer = csv.writer(the_file)\n",
    "        writer.writerow(['created_at', 'text'])\n",
    "        writer.writerows(tweets)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross check the tweets saved\n",
    "def read_tweets_from_file(hash):\n",
    "    tweets = []\n",
    "    with open('tweets_with_hashtag_'+hash+'.csv', 'r') as f:\n",
    "        reader = csv.reader(f,delimiter=',')\n",
    "        for row in reader:\n",
    "            if \"fruit\" not in row:\n",
    "                tweets.append(row)\n",
    "    \n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove http link in tweet text\n",
    "def remove_http(tweets):\n",
    "    http_removed_tweets = []\n",
    "    for idx,row in enumerate(tweets):\n",
    "        http_removed_tweets.append(re.sub('[n]?http[s]?://\\S+', '', row))\n",
    "    return http_removed_tweets   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets text cleanup\n",
    "#to remove the pattern ‘@user’ from all the tweets in our data.\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt \n",
    "\n",
    "def tweets_clean_up(get_tweets):\n",
    "\n",
    "    get_tweets = pd.DataFrame(get_tweets)\n",
    "    get_tweets.rename(columns=get_tweets.iloc[0],inplace = True)\n",
    "    get_tweets.drop(get_tweets.index[0],inplace = True)\n",
    "    #print(get_tweets.head())\n",
    "\n",
    "    # remove http link\n",
    "    get_tweets['tidy_tweet'] = remove_http(get_tweets['text'])\n",
    "\n",
    "    # remove twitter handles (@user)\n",
    "    get_tweets['tidy_tweet'] = np.vectorize(remove_pattern)(get_tweets['tidy_tweet'], \"@[\\w]*\")\n",
    "    \n",
    "    # remove special characters, numbers, punctuations\n",
    "    get_tweets['tidy_tweet'] = get_tweets['tidy_tweet'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "        \n",
    "    # removing the short words\n",
    "    get_tweets['tidy_tweet'] = get_tweets['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "        \n",
    "    return get_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization method\n",
    "def tweet_tokenization(tweet):\n",
    "    # Tokenization\n",
    "    tokenized_tweet = tweet['tidy_tweet'].apply(lambda x: x.split())    \n",
    "    return tokenized_tweet\n",
    "\n",
    "# # tokenize the tweets\n",
    "#tweets_data['tokens'] =tweet_tokenization(tweets_data)\n",
    "#tweets_data['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming / Lemmatizier\n",
    "def tweet_reduce_wordforms(tokenized_tweet):\n",
    "    #Stemming\n",
    "    #tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "    #tokenized_tweet.head()\n",
    "    \n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [lmtzr.lemmatize(i,'v') for i in x])\n",
    "    \n",
    "    for i in range(1,len(tokenized_tweet)+1):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "    return tokenized_tweet\n",
    "\n",
    "# # get tokens to baseform\n",
    "#tweets_data['tokens'] = tweet_reduce_wordforms(tweets_data['tokens'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_data = pd.read_csv(\"tweets_with_cleaned_hashtag_samsung_classification.csv\")\n",
    "train_DF = pd.DataFrame()\n",
    "train_DF['tweet_text'] = model_train_data['tidy_tweet']\n",
    "train_DF['label'] = model_train_data['Abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train_DF['tweet_text'], train_DF['label'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_word = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_word.fit(train_DF['tweet_text'])\n",
    "\n",
    "xtrain_tfidf_word =  tfidf_word.transform(train_x)\n",
    "xvalid_tfidf_word =  tfidf_word.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_ngram.fit(train_DF['tweet_text'])\n",
    "xtrain_tfidf_ngram =  tfidf_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_chars.fit(train_DF['tweet_text'])\n",
    "xtrain_tfidf_chars =  tfidf_chars.transform(train_x) \n",
    "xvalid_tfidf_chars =  tfidf_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.classification_report(predictions, valid_y)\n",
    "#accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81        31\n",
      "           1       0.74      0.84      0.79        55\n",
      "           2       0.98      0.61      0.75       138\n",
      "           3       0.42      1.00      0.59        15\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74       239\n",
      "   macro avg       0.56      0.69      0.59       239\n",
      "weighted avg       0.85      0.74      0.76       239\n",
      "\n",
      "Naive Bayes, N-Gram Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        22\n",
      "           1       0.45      0.65      0.53        43\n",
      "           2       0.90      0.46      0.61       168\n",
      "           3       0.17      1.00      0.29         6\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56       239\n",
      "   macro avg       0.40      0.62      0.41       239\n",
      "weighted avg       0.76      0.56      0.59       239\n",
      "\n",
      "Naive Bayes, CharLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.93      0.74        30\n",
      "           1       0.66      0.82      0.73        50\n",
      "           2       0.97      0.55      0.70       152\n",
      "           3       0.19      1.00      0.33         7\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67       239\n",
      "   macro avg       0.49      0.66      0.50       239\n",
      "weighted avg       0.83      0.67      0.70       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(naive_bayes.MultinomialNB(), xtrain_tfidf_word, train_y, xvalid_tfidf_word)\n",
    "print (\"Naive Bayes, WordLevel TF-IDF:\\n\" , accuracy)\n",
    "#print (\"Naive Bayes, WordLevel TF-IDF: {}%\".format(round(accuracy*100,2)))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"Naive Bayes, N-Gram Vectors:\\n\" , accuracy)\n",
    "#print( \"Navie Bayes, N-Gram Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(naive_bayes.MultinomialNB(), xtrain_tfidf_chars, train_y, xvalid_tfidf_chars)\n",
    "print (\"Naive Bayes, CharLevel TF-IDF:\\n\" , accuracy)\n",
    "#print (\"Navie Bayes, CharLevel Vectors: {}%\".format(round(accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, WordLevel TF-IDF:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        29\n",
      "           1       0.90      0.79      0.84        71\n",
      "           2       0.95      0.69      0.80       118\n",
      "           3       0.58      1.00      0.74        21\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79       239\n",
      "   macro avg       0.61      0.70      0.63       239\n",
      "weighted avg       0.87      0.79      0.81       239\n",
      "\n",
      "Logistic Regression, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54        17\n",
      "           1       0.39      0.75      0.51        32\n",
      "           2       0.94      0.44      0.60       186\n",
      "           3       0.11      1.00      0.20         4\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53       239\n",
      "   macro avg       0.36      0.64      0.37       239\n",
      "weighted avg       0.81      0.53      0.57       239\n",
      "\n",
      "Logistic Regression, CharLevel Vectors:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        40\n",
      "           1       0.84      0.80      0.82        65\n",
      "           2       0.95      0.79      0.86       104\n",
      "           3       0.81      0.97      0.88        30\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85       239\n",
      "   macro avg       0.69      0.71      0.70       239\n",
      "weighted avg       0.89      0.85      0.86       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(linear_model.LogisticRegression(), xtrain_tfidf_word, train_y, xvalid_tfidf_word)\n",
    "#print( \"Logistic Regression, WordLevel TF-IDF: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"Logistic Regression, WordLevel TF-IDF:\\n\",accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "#print (\"Logistic Regression, N-Gram Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print (\"Logistic Regression, N-Gram Vectors: \\n\",accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(linear_model.LogisticRegression(), xtrain_tfidf_chars, train_y, xvalid_tfidf_chars)\n",
    "#print( \"Logistic Regression, CharLevel Vectors:{}%\".format(round(accuracy*100,2)))\n",
    "print( \"Logistic Regression, CharLevel Vectors:\\n\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, WordLevel TF-IDF:/n%               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.36      0.53       239\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36       239\n",
      "   macro avg       0.20      0.07      0.11       239\n",
      "weighted avg       1.00      0.36      0.53       239\n",
      "\n",
      "SVM, N-Gram Vectors:\n",
      "%               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.36      0.53       239\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36       239\n",
      "   macro avg       0.20      0.07      0.11       239\n",
      "weighted avg       1.00      0.36      0.53       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.36      0.53       239\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36       239\n",
      "   macro avg       0.20      0.07      0.11       239\n",
      "weighted avg       1.00      0.36      0.53       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM on Word Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(svm.SVC(), xtrain_tfidf_word, train_y, xvalid_tfidf_word)\n",
    "#print( \"SVM, WordLevel TF-IDF: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"SVM, WordLevel TF-IDF:/n%\",accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "#print (\"SVM, N-Gram Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print (\"SVM, N-Gram Vectors:\\n%\",accuracy)\n",
    "\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(svm.SVC(), xtrain_tfidf_chars, train_y, xvalid_tfidf_chars)\n",
    "#print( \"SVM, CharLevel Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"SVM, CharLevel Vectors: \\n\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, WordLevel TF-IDF: \n",
      "%               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        33\n",
      "           1       0.97      0.63      0.76        95\n",
      "           2       0.86      0.88      0.87        84\n",
      "           3       0.67      0.92      0.77        26\n",
      "           4       0.11      1.00      0.20         1\n",
      "\n",
      "    accuracy                           0.80       239\n",
      "   macro avg       0.66      0.88      0.68       239\n",
      "weighted avg       0.86      0.80      0.81       239\n",
      "\n",
      "Random Forest, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.61        20\n",
      "           1       0.89      0.36      0.52       151\n",
      "           2       0.52      0.73      0.61        62\n",
      "           3       0.14      1.00      0.24         5\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52       239\n",
      "   macro avg       0.40      0.62      0.39       239\n",
      "weighted avg       0.74      0.52      0.54       239\n",
      "\n",
      "Random Forest, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90        41\n",
      "           1       0.89      0.71      0.79        77\n",
      "           2       0.87      0.85      0.86        88\n",
      "           3       0.78      0.90      0.84        31\n",
      "           4       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.83       239\n",
      "   macro avg       0.70      0.78      0.71       239\n",
      "weighted avg       0.85      0.83      0.84       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(ensemble.RandomForestClassifier(), xtrain_tfidf_word, train_y, xvalid_tfidf_word)\n",
    "#print (\"Random Forest, WordLevel TF-IDF: {}%\".format(round(accuracy*100,2)))\n",
    "print (\"Random Forest, WordLevel TF-IDF: \\n%\",accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "#print (\"Random Forest, N-Gram Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print (\"Random Forest, N-Gram Vectors: \\n\",accuracy)\n",
    "\n",
    "\n",
    "# SVM on Character Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(ensemble.RandomForestClassifier(), xtrain_tfidf_chars,train_y,xvalid_tfidf_chars)\n",
    "#print( \"Random Forest, CharLevel Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"Random Forest, CharLevel Vectors: \\n\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extereme Gradient Boosting, WordLevel TF-IDF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        40\n",
      "           1       1.00      0.67      0.80        93\n",
      "           2       0.88      1.00      0.94        76\n",
      "           3       0.78      1.00      0.88        28\n",
      "           4       0.22      1.00      0.36         2\n",
      "\n",
      "    accuracy                           0.85       239\n",
      "   macro avg       0.73      0.91      0.76       239\n",
      "weighted avg       0.89      0.85      0.86       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Musarath\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extereme Gradient Boosting, N-Gram Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.61        20\n",
      "           1       0.34      0.70      0.46        30\n",
      "           2       0.90      0.44      0.59       174\n",
      "           3       0.28      0.67      0.39        15\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.54       239\n",
      "   macro avg       0.39      0.56      0.41       239\n",
      "weighted avg       0.75      0.54      0.56       239\n",
      "\n",
      "Extereme Gradient Boosting, CharLevel Vectors: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        43\n",
      "           1       0.94      0.89      0.91        65\n",
      "           2       0.98      0.98      0.98        86\n",
      "           3       0.94      0.81      0.87        42\n",
      "           4       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.92       239\n",
      "   macro avg       0.82      0.93      0.84       239\n",
      "weighted avg       0.94      0.92      0.93       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(xgboost.XGBClassifier(), xtrain_tfidf_word.tocsc(), train_y, xvalid_tfidf_word.tocsc())\n",
    "#print( \"Extereme Gradient Boosting, WordLevel TF-IDF: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"Extereme Gradient Boosting, WordLevel TF-IDF: \\n\",accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Ngram Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_y, xvalid_tfidf_ngram.tocsc())\n",
    "#print( \"Extereme Gradient Boosting, N-Gram Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"Extereme Gradient Boosting, N-Gram Vectors: \\n\",accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_classifier_model(xgboost.XGBClassifier(), xtrain_tfidf_chars.tocsc(), train_y, xvalid_tfidf_chars.tocsc())\n",
    "#print( \"Extereme Gradient Boosting, CharLevel Vectors: {}%\".format(round(accuracy*100,2)))\n",
    "print( \"Extereme Gradient Boosting, CharLevel Vectors: \\n\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFIER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_final_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_new_tweets(file):\n",
    "    tweets = []\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f,delimiter=',')\n",
    "        for row in reader:\n",
    "            tweets.append(row)\n",
    "    \n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_tweets = []\n",
    "# download data\n",
    "def twitter_data_download(hash_tag):    \n",
    "    \n",
    "    # tweets download\n",
    "    twts_download = twitter_credentials(hash_tag)\n",
    "\n",
    "    # call the function        \n",
    "    write_tweets_to_file(hash_tag,twts_download)\n",
    "\n",
    "    # call read from file function\n",
    "    twitter_tweets = read_tweets_from_file(hash_tag)\n",
    "    #print(twitter_tweets)\n",
    "    \n",
    "    # tweets cleanup function\n",
    "    twitter_tweets = tweets_clean_up(twitter_tweets)\n",
    "    #print(twitter_tweets)\n",
    "    \n",
    "    return twitter_tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_data = []\n",
    "# function to tag tweets\n",
    "def twitter_abstract(tweets_data,xtrain_tfidf_word,train_y):\n",
    "    #tokenize\n",
    "    tokens_tfidf_word =  tfidf_word.transform(tweets_data['tidy_tweet'])\n",
    "\n",
    "    pred = train_classifier_final_model(xgboost.XGBClassifier(), xtrain_tfidf_word.tocsc(), train_y, tokens_tfidf_word.tocsc())\n",
    "    tweets_data['Abstract_class'] = pred\n",
    "    tweets_data['Abstract'] = encoder.inverse_transform(pred)\n",
    "    \n",
    "    #convert the date field to date format \n",
    "    df_tweets_data = pd.DataFrame(tweets_data) \n",
    "\n",
    "    #convert to date type\n",
    "    df_tweets_data['created_at'] = pd.to_datetime(df_tweets_data[\"created_at\"])\n",
    "    df_tweets_data['created_at'] = df_tweets_data['created_at'].dt.date \n",
    "    # drop the columns\n",
    "    df_tweets_data.drop(['text','Abstract_class'],axis = 1,inplace = True)\n",
    "    return df_tweets_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to calculate sentiment of each tweet\n",
    "def tweets_sentiment(df_tweet):\n",
    "    # next, we initialize VADER so we can use it within our Python script\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = []\n",
    "\n",
    "    ## Calling the polarity_scores method on sid and passing in the title \n",
    "    #outputs a dictionary with negative, neutral, positive, and compound scores for the input title\n",
    "    for tweet in df_tweet['tidy_tweet']:\n",
    "        scores = sid.polarity_scores(tweet)\n",
    "        sentiment_score.append(scores['compound'])\n",
    "\n",
    "    df_tweet['sentiment'] = sentiment_score\n",
    "    return df_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define polarity\n",
    "def tweets_polarity(df_tweets):\n",
    "    polarity = []\n",
    "    for t in df_tweets['sentiment']:\n",
    "        if t<0:\n",
    "            polarity.append(\"Negative\")\n",
    "        elif t == 0:\n",
    "            polarity.append(\"Neutral\")\n",
    "        else:\n",
    "            polarity.append(\"Positive\")\n",
    "    df_tweets['Polarity'] = polarity\n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for number of tweets per abstract over time\n",
    "def tweets_over_time(df_tweets):\n",
    "    df_daily_count = df_tweets.groupby(['created_at','Abstract'],as_index = False).agg({'tidy_tweet': \"count\"})\n",
    "\n",
    "    tmp = df_daily_count[df_daily_count['Abstract'] == 'CustomerService']\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp['created_at'], y=tmp['tidy_tweet'],\n",
    "        hoverinfo='x+y',\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5,\n",
    "                  color='rgb(131, 90, 241)'),\n",
    "        name = 'CustomerService',\n",
    "        stackgroup='one' # define stack group\n",
    "    ))\n",
    "    tmp1 = df_daily_count[df_daily_count['Abstract'] == 'News']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp1['created_at'], y=tmp1['tidy_tweet'],\n",
    "        hoverinfo='x+y',\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5,\n",
    "            color='rgb(127, 166, 238)'), \n",
    "        name = 'News',\n",
    "        stackgroup='one'\n",
    "    ))\n",
    "    tmp2 = df_daily_count[df_daily_count['Abstract'] == 'Price']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp2['created_at'], y=tmp2['tidy_tweet'],\n",
    "        hoverinfo='x+y',\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5,\n",
    "            color='rgb(111, 231, 219)'), \n",
    "        name = 'Price',\n",
    "        stackgroup='one'\n",
    "     ))\n",
    "    tmp3 = df_daily_count[df_daily_count['Abstract'] == 'Products']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp3['created_at'], y=tmp3['tidy_tweet'],\n",
    "        hoverinfo='x+y',\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5, \n",
    "            color='rgb(184, 247, 212)'),\n",
    "        name = 'Products',\n",
    "        stackgroup='one'\n",
    "     ))\n",
    "    tmp4 = df_daily_count[df_daily_count['Abstract'] == 'Recommendation']\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tmp4['created_at'], y=tmp4['tidy_tweet'],\n",
    "        hoverinfo='x+y',\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5, \n",
    "            color='rgb(95,158,160)'),\n",
    "        name = 'Recommendation',\n",
    "        stackgroup='one'\n",
    "     ))\n",
    "    fig.layout.update(title_text='Total activity over time',\n",
    "                      paper_bgcolor='rgba(0,0,0,0)',\n",
    "                    plot_bgcolor='rgba(0,0,0,0)',\n",
    "                     margin=dict(l=50, r=10, t=80, b=80))\n",
    "    fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "    \n",
    "    plot_url = py.plot(fig, filename='Tweets over time', auto_open=False,)\n",
    "    #first_plot_url = fig.write_html('first_figure.html', auto_open=True)\n",
    "    #print(plot_url)\n",
    "    #fig.show()\n",
    "    return plot_url\n",
    "    #return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to plot sentiments over all categories\n",
    "def sentiment_analysis_plot(df_tweets,hashtag):\n",
    "    #plot sentiments w.r.t abstract\n",
    "    number_of_tweets = str(len(df_tweets['tidy_tweet']))\n",
    "    df_sentiment_polarity = df_tweets.groupby(['Abstract','Polarity'],as_index = False).agg({'tidy_tweet': \"count\"})\n",
    "\n",
    "    tmp = df_sentiment_polarity[df_sentiment_polarity['Polarity'] == 'Positive']\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(    \n",
    "        y=tmp['Abstract'],\n",
    "        x=tmp['tidy_tweet'] ,\n",
    "        name='Positive',\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color='green',\n",
    "        )\n",
    "    ))\n",
    "    tmp1 = df_sentiment_polarity[df_sentiment_polarity['Polarity'] == 'Neutral']\n",
    "    fig.add_trace(go.Bar(    \n",
    "        y=tmp1['Abstract'],\n",
    "        x=tmp1['tidy_tweet'],\n",
    "        name='Neutral',\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color='gold',\n",
    "        )\n",
    "    ))\n",
    "    tmp2 = df_sentiment_polarity[df_sentiment_polarity['Polarity'] == 'Negative']\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=tmp2['Abstract'],\n",
    "        x=tmp2['tidy_tweet'],\n",
    "        name='Negative',\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color='red',\n",
    "        )\n",
    "    ))\n",
    "    fig.layout.update(barmode='stack',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        #paper_bgcolor='rgb(248, 248, 255)',\n",
    "        #plot_bgcolor='rgb(248, 248, 255)',\n",
    "        margin=dict(l=100, r=10, t=80, b=80),\n",
    "    )\n",
    "    fig.layout.update(title_text='Data gathered from the analysis of '+ number_of_tweets +' twitter reviews on '+ hashtag.upper())\n",
    "    fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "    #fig.show()\n",
    "    plot_url = py.plot(fig, filename='Tweets Sentiment', auto_open=False,)\n",
    "    \n",
    "    return plot_url\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_categorize(df_tweets):\n",
    "    # categorize sentiment into different categories\n",
    "    tweets_sent_cat = []\n",
    "    #df_tweets_1 = {'sentiment': [0.35,0.4]}\n",
    "    #df_tweets_1 = pd.DataFrame(df_tweets_1)\n",
    "    for t in df_tweets['sentiment']:\n",
    "        if t == 0:\n",
    "            tweets_sent_cat.append(\"fair\") \n",
    "        elif t <= -0.9:\n",
    "            tweets_sent_cat.append(\"Unpleasant\")\n",
    "        elif t > -0.9 and t <= -0.7:\n",
    "             tweets_sent_cat.append(\"disgust\")\n",
    "        elif t > -0.7 and t <= -0.4:\n",
    "             tweets_sent_cat.append(\"upset\")\n",
    "        elif t < 0 and t > -0.4:\n",
    "             tweets_sent_cat.append(\"sadness\")\n",
    "        elif t >= 0.9:\n",
    "            tweets_sent_cat.append(\"pleasant\")\n",
    "        elif t >= 0.7 and t < 0.9:\n",
    "             tweets_sent_cat.append(\"elate\")\n",
    "        elif t >= 0.4 and t < 0.7:\n",
    "             tweets_sent_cat.append(\"excited\")\n",
    "        elif t >0 and t < 0.4:\n",
    "             tweets_sent_cat.append(\"happy\")\n",
    "\n",
    "    df_tweets['tweets_sent_cat'] =  tweets_sent_cat\n",
    "    \n",
    "    return df_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# method to plot spiral plot of sentiments\n",
    "def tweets_spiral(df_tweets):\n",
    "    df_tweets_sent_cat = df_tweets.groupby(['Abstract','tweets_sent_cat'],as_index = False).agg({'tidy_tweet': \"count\"})\n",
    "    #df_tweets_sent_cat\n",
    "\n",
    "    #plot the chart\n",
    "    fig = px.bar_polar(df_tweets_sent_cat, r=\"tidy_tweet\", theta=\"tweets_sent_cat\",\n",
    "                        color=\"Abstract\",template=\"seaborn\",\n",
    "                       color_discrete_sequence= px.colors.sequential.Plasma[-2::-1])\n",
    "    fig.layout.update(title_text='Sentiments spiral')\n",
    "    fig.update_layout(legend_orientation=\"h\",\n",
    "                      margin=dict(l=80, r=80, t=80, b=100),\n",
    "                     paper_bgcolor='rgba(0,0,0,0)')\n",
    "    \n",
    "    #fig.show()\n",
    "    plot_url = py.plot(fig, filename='Tweets Spiral Sentiment', auto_open=False,)\n",
    "    \n",
    "    return plot_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to display all tweets for the given hashtag in a table\n",
    "def tweets_table(df_tweets,hashtag):\n",
    "    df_tweets = df_tweets.loc[1:3000]\n",
    "    values = [list(df_tweets['created_at']), #1st col\n",
    "      list(df_tweets['tidy_tweet']),\n",
    "      list(df_tweets['Abstract'])]\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "      columnorder = [1,2,3],\n",
    "      columnwidth = [80,400,80],\n",
    "      header = dict(\n",
    "        values = [['<b>CREATED_AT</b>'],\n",
    "                    ['<b>TWEETS</b>'],\n",
    "                 ['<b>ABSTRACT</b>']],\n",
    "        line_color='darkslategray',\n",
    "        fill_color='royalblue',\n",
    "        align=['left','center'],\n",
    "        font=dict(color='white', size=12),\n",
    "        height=40\n",
    "      ),\n",
    "      cells=dict(\n",
    "        values=values,\n",
    "        line_color='darkslategray',\n",
    "        fill=dict(color=['white','white', 'paleturquoise']),\n",
    "        align=['left', 'center'],\n",
    "        font_size=12,\n",
    "        height=30)\n",
    "        )\n",
    "    ])\n",
    "    fig.layout.update(title_text='Tweets on #'+hashtag.upper(),\n",
    "                      paper_bgcolor='rgba(0,0,0,0)',\n",
    "                     font=dict(\n",
    "                             family=\"Courier New, monospace\",\n",
    "                             size=18,\n",
    "                             color=\"#7f7f7f\"\n",
    "            ))\n",
    "\n",
    "    \n",
    "    #fig.show()\n",
    "    plot_url = py.plot(fig, filename='Tweets Table', auto_open=False,weight = \"bold\")\n",
    "    \n",
    "    return plot_url\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPORT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_html_string(hashtag,p1,p2,t1,p3):\n",
    "    print(hashtag)\n",
    "    html_string = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css\">\n",
    "            <style>body{ margin:0 100; background:whitesmoke; }</style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1><img src = \"https://1000logos.net/wp-content/uploads/2017/06/Twitter-Logo.png\" alt = \"Twitter\" \n",
    "            width=\"100\" height=\"100\">Twitter Review Analysis on #'''+ hashtag.upper() + ''' </h1> \n",
    "            <!-- Add icon library -->\n",
    "        \n",
    "            \n",
    "            <!-- *** Section 1 *** ---> \n",
    "            <!--<h2>Tweets over time</h2>-->\n",
    "            <iframe width=\"700\" height=\"400\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "    src=\"''' + p1 + '''\"></iframe>\n",
    "             <!-- *** Section 2 *** --->\n",
    "            <!--<h2>Tweets Sentiment Analysis</h2>-->\n",
    "            <iframe width= \"600\" height=\"400\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "    src=\"''' + p2 + '''\"></iframe> \n",
    "            <!--<h2>Twitter Reviews</h2>-->\n",
    "            <iframe width=\"800\" height=\"500\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "    src=\"''' + t1 + '''\"></iframe> \n",
    "            <!--<h2>Sentiment Spiral</h2>-->\n",
    "            <iframe width=\"500\" height=\"500\" frameborder=\"0\" seamless=\"seamless\" scrolling=\"no\" \\\n",
    "    src=\"''' + p3 + '''\"></iframe> \n",
    "\n",
    "        </body>\n",
    "    </html>'''\n",
    "    \n",
    "    return html_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to create a report html\n",
    "def write_to_html(hashtag,html_string):\n",
    "    f = open('C:/Users/Musarath/Musarath/Anly699_Project/Anly699_TwitterAnalytics_MusarathR/Twitter_Analytics_App_Code/Templates/'+hashtag+'_report.html','w')\n",
    "    f.write(html_string)\n",
    "    f.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWITTER ANALYTICS APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new_run() got an unexpected keyword argument 'host'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-180bea8f13f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# main function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.0.0.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: new_run() got an unexpected keyword argument 'host'"
     ]
    }
   ],
   "source": [
    "global str\n",
    "from flask import Flask\n",
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "# to get information from my-form page\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('my-report.html')\n",
    "\n",
    "# to post the result to web page\n",
    "@app.route('/',methods=['POST'])\n",
    "def my_hashtag_report():\n",
    "\n",
    "    # read the batch file\n",
    "    hashtag = str(request.form['string'])   # get the url and store in varaible\n",
    "    print(hashtag)\n",
    "\n",
    "    # get data\n",
    "    tweets_data = twitter_data_download(hashtag)\n",
    "\n",
    "    # tag the tweets\n",
    "    df_tweets = twitter_abstract(tweets_data,xtrain_tfidf_word,train_y)\n",
    "    # sentiment\n",
    "    df_tweets = tweets_sentiment(df_tweets)\n",
    "    # polarity\n",
    "    df_tweets = tweets_polarity(df_tweets)\n",
    "    # sentiment categorize\n",
    "    df_tweets = sentiment_categorize(df_tweets)\n",
    "\n",
    "    # plot generations\n",
    "    tweets_over_time_plot_url = tweets_over_time(df_tweets)\n",
    "    tweets_sentiment_plot_url = sentiment_analysis_plot(df_tweets,hashtag)\n",
    "    all_tweets_table = tweets_table(df_tweets,hashtag)\n",
    "    sentiment_spiral_plot_url = tweets_spiral(df_tweets)\n",
    "    # create report\n",
    "    html_string = define_html_string(hashtag,tweets_over_time_plot_url,tweets_sentiment_plot_url,all_tweets_table,sentiment_spiral_plot_url)\n",
    "    write_to_html(hashtag,html_string)\n",
    "\n",
    "    # open the report\n",
    "    #webbrowser.open_new_tab( 'C:/Users/Musarath/Musarath/Anly699_Project/'+hashtag+'_report.html')    \n",
    "\n",
    "    filename = str(hashtag+'_report.html')\n",
    "    return render_template(filename)\n",
    "        \n",
    "        \n",
    "# main function\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
